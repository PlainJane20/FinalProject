{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0c8xyziKl-B"
   },
   "source": [
    "**Image Recognition in Pyhton with Tenserflow and Keras**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkVOdBGlcZpF",
    "outputId": "67ec06c3-2640-4425-c053-060736908188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mKeoVQLqz1YW"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1fxzO8Pr0GRv"
   },
   "outputs": [],
   "source": [
    "# Set random seed for purposes of reproducibility\n",
    "seed = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8skd8Q8s0Z4X"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZ26qMSS0j45",
    "outputId": "1c31bd49-e9de-41d1-f072-b002bf0fddb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# loading in the data\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xEhnAzvE1EIU"
   },
   "outputs": [],
   "source": [
    "# normalize the inputs from 0-255 to between 0 and 1 by dividing by 255\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tgvvrqhUJqm0"
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "class_num = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JX3L716KfRy"
   },
   "source": [
    "**Create the Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6rKxWv4oKNWS"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lU5wyBm5LFqy"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NUaSyoIOMqiM"
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TQnnRSOAMxH7"
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZoQc768yM26m"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kJb74ByNM_mY"
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GV-x93g2NUpm"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tZFdDAt6NfZj"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jyhKLaRDNsFz"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LO8sVWU2Numa"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(class_num))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pVlkjDhbN7XJ"
   },
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CRQLzIDJOGdT"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzKQjLWUOMd9",
    "outputId": "575d167c-83ae-40cf-b67c-62a2da53eadb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,276,068\n",
      "Trainable params: 2,274,724\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8gVCVnC3dFyf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4g4aHBICcpB4"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ly_Km1yWOUYq",
    "outputId": "653dcede-002e-4636-e443-362c82911e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "782/782 [==============================] - 43s 12ms/step - loss: 4.1719 - accuracy: 0.0853 - val_loss: 3.5499 - val_accuracy: 0.1577\n",
      "Epoch 2/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 3.2128 - accuracy: 0.2159 - val_loss: 2.7002 - val_accuracy: 0.3184\n",
      "Epoch 3/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 2.7790 - accuracy: 0.2940 - val_loss: 2.5201 - val_accuracy: 0.3523\n",
      "Epoch 4/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 2.4843 - accuracy: 0.3510 - val_loss: 2.2651 - val_accuracy: 0.4086\n",
      "Epoch 5/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 2.3163 - accuracy: 0.3930 - val_loss: 2.3597 - val_accuracy: 0.3900\n",
      "Epoch 6/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 2.1882 - accuracy: 0.4180 - val_loss: 2.1354 - val_accuracy: 0.4324\n",
      "Epoch 7/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 2.0749 - accuracy: 0.4428 - val_loss: 2.1197 - val_accuracy: 0.4372\n",
      "Epoch 8/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 2.0235 - accuracy: 0.4500 - val_loss: 2.0221 - val_accuracy: 0.4528\n",
      "Epoch 9/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.9668 - accuracy: 0.4632 - val_loss: 1.9130 - val_accuracy: 0.4792\n",
      "Epoch 10/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.9050 - accuracy: 0.4789 - val_loss: 2.0331 - val_accuracy: 0.4556\n",
      "Epoch 11/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.8745 - accuracy: 0.4865 - val_loss: 1.9329 - val_accuracy: 0.4859\n",
      "Epoch 12/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.8216 - accuracy: 0.4941 - val_loss: 1.8564 - val_accuracy: 0.4990\n",
      "Epoch 13/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.7976 - accuracy: 0.5012 - val_loss: 1.8292 - val_accuracy: 0.5022\n",
      "Epoch 14/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.7616 - accuracy: 0.5107 - val_loss: 1.8692 - val_accuracy: 0.4968\n",
      "Epoch 15/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.7289 - accuracy: 0.5206 - val_loss: 1.8720 - val_accuracy: 0.4917\n",
      "Epoch 16/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.7025 - accuracy: 0.5282 - val_loss: 1.7858 - val_accuracy: 0.5148\n",
      "Epoch 17/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.7109 - accuracy: 0.5210 - val_loss: 1.8646 - val_accuracy: 0.5023\n",
      "Epoch 18/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.6734 - accuracy: 0.5331 - val_loss: 1.7869 - val_accuracy: 0.5157\n",
      "Epoch 19/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.6532 - accuracy: 0.5404 - val_loss: 1.7906 - val_accuracy: 0.5167\n",
      "Epoch 20/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.6361 - accuracy: 0.5430 - val_loss: 1.8075 - val_accuracy: 0.5109\n",
      "Epoch 21/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.6205 - accuracy: 0.5493 - val_loss: 1.7915 - val_accuracy: 0.5116\n",
      "Epoch 22/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.6017 - accuracy: 0.5475 - val_loss: 1.8446 - val_accuracy: 0.5045\n",
      "Epoch 23/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5957 - accuracy: 0.5509 - val_loss: 1.7790 - val_accuracy: 0.5188\n",
      "Epoch 24/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5767 - accuracy: 0.5532 - val_loss: 1.7045 - val_accuracy: 0.5373\n",
      "Epoch 25/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5575 - accuracy: 0.5619 - val_loss: 1.8181 - val_accuracy: 0.5126\n",
      "Epoch 26/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5625 - accuracy: 0.5566 - val_loss: 1.7245 - val_accuracy: 0.5301\n",
      "Epoch 27/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5400 - accuracy: 0.5614 - val_loss: 1.7130 - val_accuracy: 0.5347\n",
      "Epoch 28/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5199 - accuracy: 0.5676 - val_loss: 1.7272 - val_accuracy: 0.5313\n",
      "Epoch 29/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5406 - accuracy: 0.5592 - val_loss: 1.7238 - val_accuracy: 0.5351\n",
      "Epoch 30/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5261 - accuracy: 0.5660 - val_loss: 1.7439 - val_accuracy: 0.5266\n",
      "Epoch 31/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.5092 - accuracy: 0.5713 - val_loss: 1.7147 - val_accuracy: 0.5326\n",
      "Epoch 32/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4969 - accuracy: 0.5713 - val_loss: 1.7244 - val_accuracy: 0.5315\n",
      "Epoch 33/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4920 - accuracy: 0.5753 - val_loss: 1.7498 - val_accuracy: 0.5301\n",
      "Epoch 34/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4927 - accuracy: 0.5767 - val_loss: 1.7291 - val_accuracy: 0.5356\n",
      "Epoch 35/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4802 - accuracy: 0.5756 - val_loss: 1.7152 - val_accuracy: 0.5303\n",
      "Epoch 36/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4696 - accuracy: 0.5790 - val_loss: 1.7203 - val_accuracy: 0.5342\n",
      "Epoch 37/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4610 - accuracy: 0.5788 - val_loss: 1.7580 - val_accuracy: 0.5274\n",
      "Epoch 38/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4587 - accuracy: 0.5825 - val_loss: 1.6680 - val_accuracy: 0.5443\n",
      "Epoch 39/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4729 - accuracy: 0.5772 - val_loss: 1.6837 - val_accuracy: 0.5416\n",
      "Epoch 40/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4664 - accuracy: 0.5815 - val_loss: 1.6948 - val_accuracy: 0.5371\n",
      "Epoch 41/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4571 - accuracy: 0.5840 - val_loss: 1.7192 - val_accuracy: 0.5338\n",
      "Epoch 42/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4361 - accuracy: 0.5891 - val_loss: 1.6805 - val_accuracy: 0.5432\n",
      "Epoch 43/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4382 - accuracy: 0.5885 - val_loss: 1.6865 - val_accuracy: 0.5351\n",
      "Epoch 44/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4392 - accuracy: 0.5898 - val_loss: 1.6766 - val_accuracy: 0.5431\n",
      "Epoch 45/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4224 - accuracy: 0.5922 - val_loss: 1.6628 - val_accuracy: 0.5435\n",
      "Epoch 46/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4205 - accuracy: 0.5933 - val_loss: 1.6792 - val_accuracy: 0.5475\n",
      "Epoch 47/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4197 - accuracy: 0.5901 - val_loss: 1.6404 - val_accuracy: 0.5558\n",
      "Epoch 48/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4135 - accuracy: 0.5922 - val_loss: 1.6464 - val_accuracy: 0.5496\n",
      "Epoch 49/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4125 - accuracy: 0.5958 - val_loss: 1.6493 - val_accuracy: 0.5509\n",
      "Epoch 50/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3976 - accuracy: 0.5980 - val_loss: 1.6457 - val_accuracy: 0.5515\n",
      "Epoch 51/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.4067 - accuracy: 0.5939 - val_loss: 1.6419 - val_accuracy: 0.5539\n",
      "Epoch 52/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3908 - accuracy: 0.5980 - val_loss: 1.6881 - val_accuracy: 0.5412\n",
      "Epoch 53/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3960 - accuracy: 0.5977 - val_loss: 1.6678 - val_accuracy: 0.5471\n",
      "Epoch 54/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3841 - accuracy: 0.6026 - val_loss: 1.6666 - val_accuracy: 0.5481\n",
      "Epoch 55/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3912 - accuracy: 0.6000 - val_loss: 1.6939 - val_accuracy: 0.5463\n",
      "Epoch 56/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3870 - accuracy: 0.5992 - val_loss: 1.6394 - val_accuracy: 0.5524\n",
      "Epoch 57/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3848 - accuracy: 0.6023 - val_loss: 1.5982 - val_accuracy: 0.5597\n",
      "Epoch 58/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3722 - accuracy: 0.6081 - val_loss: 1.6842 - val_accuracy: 0.5448\n",
      "Epoch 59/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3615 - accuracy: 0.6079 - val_loss: 1.6046 - val_accuracy: 0.5582\n",
      "Epoch 60/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3497 - accuracy: 0.6118 - val_loss: 1.6620 - val_accuracy: 0.5457\n",
      "Epoch 61/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3793 - accuracy: 0.6021 - val_loss: 1.6134 - val_accuracy: 0.5580\n",
      "Epoch 62/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3749 - accuracy: 0.6006 - val_loss: 1.6835 - val_accuracy: 0.5449\n",
      "Epoch 63/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3783 - accuracy: 0.5973 - val_loss: 1.6662 - val_accuracy: 0.5490\n",
      "Epoch 64/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3558 - accuracy: 0.6069 - val_loss: 1.6436 - val_accuracy: 0.5510\n",
      "Epoch 65/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3607 - accuracy: 0.6070 - val_loss: 1.6579 - val_accuracy: 0.5447\n",
      "Epoch 66/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3504 - accuracy: 0.6150 - val_loss: 1.6813 - val_accuracy: 0.5441\n",
      "Epoch 67/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3644 - accuracy: 0.6040 - val_loss: 1.6525 - val_accuracy: 0.5486\n",
      "Epoch 68/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3555 - accuracy: 0.6082 - val_loss: 1.6257 - val_accuracy: 0.5549\n",
      "Epoch 69/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3324 - accuracy: 0.6125 - val_loss: 1.6207 - val_accuracy: 0.5655\n",
      "Epoch 70/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3281 - accuracy: 0.6201 - val_loss: 1.6264 - val_accuracy: 0.5559\n",
      "Epoch 71/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3502 - accuracy: 0.6069 - val_loss: 1.6866 - val_accuracy: 0.5472\n",
      "Epoch 72/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3350 - accuracy: 0.6137 - val_loss: 1.6099 - val_accuracy: 0.5551\n",
      "Epoch 73/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3289 - accuracy: 0.6150 - val_loss: 1.6471 - val_accuracy: 0.5546\n",
      "Epoch 74/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3330 - accuracy: 0.6134 - val_loss: 1.5962 - val_accuracy: 0.5566\n",
      "Epoch 75/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3421 - accuracy: 0.6087 - val_loss: 1.6162 - val_accuracy: 0.5581\n",
      "Epoch 76/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3268 - accuracy: 0.6163 - val_loss: 1.6130 - val_accuracy: 0.5585\n",
      "Epoch 77/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3282 - accuracy: 0.6161 - val_loss: 1.6417 - val_accuracy: 0.5524\n",
      "Epoch 78/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3333 - accuracy: 0.6153 - val_loss: 1.5972 - val_accuracy: 0.5605\n",
      "Epoch 79/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3387 - accuracy: 0.6105 - val_loss: 1.6366 - val_accuracy: 0.5531\n",
      "Epoch 80/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3317 - accuracy: 0.6147 - val_loss: 1.5825 - val_accuracy: 0.5672\n",
      "Epoch 81/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3087 - accuracy: 0.6171 - val_loss: 1.7433 - val_accuracy: 0.5361\n",
      "Epoch 82/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3306 - accuracy: 0.6169 - val_loss: 1.6010 - val_accuracy: 0.5681\n",
      "Epoch 83/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3222 - accuracy: 0.6159 - val_loss: 1.6421 - val_accuracy: 0.5517\n",
      "Epoch 84/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3131 - accuracy: 0.6198 - val_loss: 1.5792 - val_accuracy: 0.5694\n",
      "Epoch 85/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3046 - accuracy: 0.6211 - val_loss: 1.6462 - val_accuracy: 0.5550\n",
      "Epoch 86/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2986 - accuracy: 0.6229 - val_loss: 1.5742 - val_accuracy: 0.5716\n",
      "Epoch 87/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3118 - accuracy: 0.6176 - val_loss: 1.6098 - val_accuracy: 0.5644\n",
      "Epoch 88/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3103 - accuracy: 0.6213 - val_loss: 1.5538 - val_accuracy: 0.5726\n",
      "Epoch 89/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3047 - accuracy: 0.6201 - val_loss: 1.6326 - val_accuracy: 0.5537\n",
      "Epoch 90/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2978 - accuracy: 0.6227 - val_loss: 1.5578 - val_accuracy: 0.5693\n",
      "Epoch 91/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2961 - accuracy: 0.6223 - val_loss: 1.6330 - val_accuracy: 0.5594\n",
      "Epoch 92/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3019 - accuracy: 0.6202 - val_loss: 1.6033 - val_accuracy: 0.5600\n",
      "Epoch 93/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3064 - accuracy: 0.6226 - val_loss: 1.6011 - val_accuracy: 0.5673\n",
      "Epoch 94/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2903 - accuracy: 0.6255 - val_loss: 1.6027 - val_accuracy: 0.5623\n",
      "Epoch 95/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2945 - accuracy: 0.6218 - val_loss: 1.6197 - val_accuracy: 0.5580\n",
      "Epoch 96/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2949 - accuracy: 0.6255 - val_loss: 1.5932 - val_accuracy: 0.5623\n",
      "Epoch 97/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2793 - accuracy: 0.6259 - val_loss: 1.5739 - val_accuracy: 0.5690\n",
      "Epoch 98/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2931 - accuracy: 0.6205 - val_loss: 1.6092 - val_accuracy: 0.5612\n",
      "Epoch 99/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2805 - accuracy: 0.6247 - val_loss: 1.5741 - val_accuracy: 0.5681\n",
      "Epoch 100/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2869 - accuracy: 0.6241 - val_loss: 1.5927 - val_accuracy: 0.5682\n",
      "Epoch 101/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2709 - accuracy: 0.6283 - val_loss: 1.5826 - val_accuracy: 0.5683\n",
      "Epoch 102/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2964 - accuracy: 0.6212 - val_loss: 1.5644 - val_accuracy: 0.5750\n",
      "Epoch 103/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.3019 - accuracy: 0.6224 - val_loss: 1.5651 - val_accuracy: 0.5696\n",
      "Epoch 104/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2715 - accuracy: 0.6276 - val_loss: 1.5766 - val_accuracy: 0.5685\n",
      "Epoch 105/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2867 - accuracy: 0.6239 - val_loss: 1.5828 - val_accuracy: 0.5647\n",
      "Epoch 106/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2774 - accuracy: 0.6278 - val_loss: 1.5919 - val_accuracy: 0.5711\n",
      "Epoch 107/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2584 - accuracy: 0.6334 - val_loss: 1.5922 - val_accuracy: 0.5648\n",
      "Epoch 108/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2876 - accuracy: 0.6231 - val_loss: 1.5668 - val_accuracy: 0.5711\n",
      "Epoch 109/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2692 - accuracy: 0.6290 - val_loss: 1.5789 - val_accuracy: 0.5659\n",
      "Epoch 110/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2715 - accuracy: 0.6281 - val_loss: 1.6136 - val_accuracy: 0.5586\n",
      "Epoch 111/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2745 - accuracy: 0.6249 - val_loss: 1.6703 - val_accuracy: 0.5519\n",
      "Epoch 112/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2700 - accuracy: 0.6265 - val_loss: 1.5831 - val_accuracy: 0.5722\n",
      "Epoch 113/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2772 - accuracy: 0.6283 - val_loss: 1.5828 - val_accuracy: 0.5650\n",
      "Epoch 114/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2603 - accuracy: 0.6297 - val_loss: 1.5704 - val_accuracy: 0.5684\n",
      "Epoch 115/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2630 - accuracy: 0.6301 - val_loss: 1.5649 - val_accuracy: 0.5730\n",
      "Epoch 116/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2720 - accuracy: 0.6303 - val_loss: 1.5386 - val_accuracy: 0.5800\n",
      "Epoch 117/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2400 - accuracy: 0.6340 - val_loss: 1.6090 - val_accuracy: 0.5592\n",
      "Epoch 118/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2594 - accuracy: 0.6292 - val_loss: 1.5778 - val_accuracy: 0.5694\n",
      "Epoch 119/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2632 - accuracy: 0.6332 - val_loss: 1.6135 - val_accuracy: 0.5620\n",
      "Epoch 120/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2582 - accuracy: 0.6339 - val_loss: 1.5574 - val_accuracy: 0.5732\n",
      "Epoch 121/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2486 - accuracy: 0.6319 - val_loss: 1.6352 - val_accuracy: 0.5589\n",
      "Epoch 122/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2480 - accuracy: 0.6360 - val_loss: 1.5525 - val_accuracy: 0.5759\n",
      "Epoch 123/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2533 - accuracy: 0.6331 - val_loss: 1.5335 - val_accuracy: 0.5809\n",
      "Epoch 124/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2741 - accuracy: 0.6239 - val_loss: 1.5616 - val_accuracy: 0.5735\n",
      "Epoch 125/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2544 - accuracy: 0.6335 - val_loss: 1.5744 - val_accuracy: 0.5698\n",
      "Epoch 126/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2560 - accuracy: 0.6314 - val_loss: 1.6244 - val_accuracy: 0.5628\n",
      "Epoch 127/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2963 - accuracy: 0.6212 - val_loss: 1.5866 - val_accuracy: 0.5699\n",
      "Epoch 128/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2581 - accuracy: 0.6313 - val_loss: 1.6004 - val_accuracy: 0.5647\n",
      "Epoch 129/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2520 - accuracy: 0.6363 - val_loss: 1.5621 - val_accuracy: 0.5730\n",
      "Epoch 130/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2569 - accuracy: 0.6286 - val_loss: 1.5448 - val_accuracy: 0.5775\n",
      "Epoch 131/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2357 - accuracy: 0.6401 - val_loss: 1.5683 - val_accuracy: 0.5674\n",
      "Epoch 132/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2422 - accuracy: 0.6371 - val_loss: 1.5739 - val_accuracy: 0.5709\n",
      "Epoch 133/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2515 - accuracy: 0.6332 - val_loss: 1.5470 - val_accuracy: 0.5759\n",
      "Epoch 134/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2480 - accuracy: 0.6323 - val_loss: 1.5654 - val_accuracy: 0.5708\n",
      "Epoch 135/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2510 - accuracy: 0.6347 - val_loss: 1.6001 - val_accuracy: 0.5624\n",
      "Epoch 136/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2375 - accuracy: 0.6393 - val_loss: 1.5684 - val_accuracy: 0.5741\n",
      "Epoch 137/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2484 - accuracy: 0.6357 - val_loss: 1.5753 - val_accuracy: 0.5702\n",
      "Epoch 138/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2401 - accuracy: 0.6363 - val_loss: 1.5293 - val_accuracy: 0.5803\n",
      "Epoch 139/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2390 - accuracy: 0.6374 - val_loss: 1.5599 - val_accuracy: 0.5740\n",
      "Epoch 140/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2383 - accuracy: 0.6333 - val_loss: 1.5616 - val_accuracy: 0.5720\n",
      "Epoch 141/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2418 - accuracy: 0.6363 - val_loss: 1.5669 - val_accuracy: 0.5694\n",
      "Epoch 142/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2463 - accuracy: 0.6333 - val_loss: 1.5440 - val_accuracy: 0.5786\n",
      "Epoch 143/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2318 - accuracy: 0.6385 - val_loss: 1.5577 - val_accuracy: 0.5704\n",
      "Epoch 144/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2455 - accuracy: 0.6315 - val_loss: 1.5602 - val_accuracy: 0.5734\n",
      "Epoch 145/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2368 - accuracy: 0.6406 - val_loss: 1.5862 - val_accuracy: 0.5740\n",
      "Epoch 146/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2219 - accuracy: 0.6419 - val_loss: 1.5887 - val_accuracy: 0.5717\n",
      "Epoch 147/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2199 - accuracy: 0.6408 - val_loss: 1.5286 - val_accuracy: 0.5814\n",
      "Epoch 148/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2411 - accuracy: 0.6345 - val_loss: 1.5704 - val_accuracy: 0.5715\n",
      "Epoch 149/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2363 - accuracy: 0.6359 - val_loss: 1.5313 - val_accuracy: 0.5792\n",
      "Epoch 150/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2256 - accuracy: 0.6402 - val_loss: 1.5607 - val_accuracy: 0.5743\n",
      "Epoch 151/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2498 - accuracy: 0.6354 - val_loss: 1.5818 - val_accuracy: 0.5735\n",
      "Epoch 152/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2363 - accuracy: 0.6403 - val_loss: 1.5790 - val_accuracy: 0.5699\n",
      "Epoch 153/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2194 - accuracy: 0.6450 - val_loss: 1.5440 - val_accuracy: 0.5791\n",
      "Epoch 154/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2283 - accuracy: 0.6388 - val_loss: 1.6029 - val_accuracy: 0.5676\n",
      "Epoch 155/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2121 - accuracy: 0.6417 - val_loss: 1.5536 - val_accuracy: 0.5753\n",
      "Epoch 156/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2287 - accuracy: 0.6397 - val_loss: 1.5760 - val_accuracy: 0.5716\n",
      "Epoch 157/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2207 - accuracy: 0.6385 - val_loss: 1.5747 - val_accuracy: 0.5691\n",
      "Epoch 158/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2395 - accuracy: 0.6363 - val_loss: 1.5758 - val_accuracy: 0.5732\n",
      "Epoch 159/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2306 - accuracy: 0.6410 - val_loss: 1.5408 - val_accuracy: 0.5843\n",
      "Epoch 160/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2206 - accuracy: 0.6424 - val_loss: 1.5604 - val_accuracy: 0.5759\n",
      "Epoch 161/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2028 - accuracy: 0.6432 - val_loss: 1.5598 - val_accuracy: 0.5711\n",
      "Epoch 162/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2071 - accuracy: 0.6460 - val_loss: 1.5583 - val_accuracy: 0.5767\n",
      "Epoch 163/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2189 - accuracy: 0.6398 - val_loss: 1.5616 - val_accuracy: 0.5743\n",
      "Epoch 164/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2197 - accuracy: 0.6388 - val_loss: 1.5836 - val_accuracy: 0.5677\n",
      "Epoch 165/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2309 - accuracy: 0.6392 - val_loss: 1.5726 - val_accuracy: 0.5726\n",
      "Epoch 166/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2093 - accuracy: 0.6406 - val_loss: 1.5532 - val_accuracy: 0.5750\n",
      "Epoch 167/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2063 - accuracy: 0.6439 - val_loss: 1.5745 - val_accuracy: 0.5720\n",
      "Epoch 168/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2340 - accuracy: 0.6395 - val_loss: 1.5520 - val_accuracy: 0.5727\n",
      "Epoch 169/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2060 - accuracy: 0.6424 - val_loss: 1.5569 - val_accuracy: 0.5777\n",
      "Epoch 170/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2197 - accuracy: 0.6409 - val_loss: 1.5592 - val_accuracy: 0.5816\n",
      "Epoch 171/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2237 - accuracy: 0.6404 - val_loss: 1.6114 - val_accuracy: 0.5725\n",
      "Epoch 172/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2065 - accuracy: 0.6417 - val_loss: 1.5585 - val_accuracy: 0.5759\n",
      "Epoch 173/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2198 - accuracy: 0.6469 - val_loss: 1.5593 - val_accuracy: 0.5784\n",
      "Epoch 174/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1979 - accuracy: 0.6443 - val_loss: 1.6072 - val_accuracy: 0.5675\n",
      "Epoch 175/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2160 - accuracy: 0.6403 - val_loss: 1.5491 - val_accuracy: 0.5743\n",
      "Epoch 176/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2151 - accuracy: 0.6406 - val_loss: 1.5261 - val_accuracy: 0.5832\n",
      "Epoch 177/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2064 - accuracy: 0.6447 - val_loss: 1.5507 - val_accuracy: 0.5795\n",
      "Epoch 178/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2028 - accuracy: 0.6438 - val_loss: 1.5731 - val_accuracy: 0.5815\n",
      "Epoch 179/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1940 - accuracy: 0.6506 - val_loss: 1.5399 - val_accuracy: 0.5818\n",
      "Epoch 180/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2201 - accuracy: 0.6386 - val_loss: 1.5224 - val_accuracy: 0.5823\n",
      "Epoch 181/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2074 - accuracy: 0.6418 - val_loss: 1.5793 - val_accuracy: 0.5705\n",
      "Epoch 182/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2070 - accuracy: 0.6438 - val_loss: 1.5307 - val_accuracy: 0.5805\n",
      "Epoch 183/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1954 - accuracy: 0.6476 - val_loss: 1.5615 - val_accuracy: 0.5745\n",
      "Epoch 184/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2032 - accuracy: 0.6437 - val_loss: 1.5637 - val_accuracy: 0.5754\n",
      "Epoch 185/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2079 - accuracy: 0.6402 - val_loss: 1.5384 - val_accuracy: 0.5799\n",
      "Epoch 186/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2161 - accuracy: 0.6409 - val_loss: 1.5555 - val_accuracy: 0.5737\n",
      "Epoch 187/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2040 - accuracy: 0.6458 - val_loss: 1.5901 - val_accuracy: 0.5688\n",
      "Epoch 188/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2038 - accuracy: 0.6453 - val_loss: 1.5087 - val_accuracy: 0.5878\n",
      "Epoch 189/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.2145 - accuracy: 0.6441 - val_loss: 1.5470 - val_accuracy: 0.5745\n",
      "Epoch 190/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2033 - accuracy: 0.6457 - val_loss: 1.5491 - val_accuracy: 0.5831\n",
      "Epoch 191/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2003 - accuracy: 0.6459 - val_loss: 1.5091 - val_accuracy: 0.5840\n",
      "Epoch 192/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2029 - accuracy: 0.6453 - val_loss: 1.5380 - val_accuracy: 0.5763\n",
      "Epoch 193/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2044 - accuracy: 0.6504 - val_loss: 1.5394 - val_accuracy: 0.5771\n",
      "Epoch 194/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1945 - accuracy: 0.6476 - val_loss: 1.5460 - val_accuracy: 0.5795\n",
      "Epoch 195/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1937 - accuracy: 0.6495 - val_loss: 1.5433 - val_accuracy: 0.5809\n",
      "Epoch 196/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2141 - accuracy: 0.6467 - val_loss: 1.5454 - val_accuracy: 0.5788\n",
      "Epoch 197/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2123 - accuracy: 0.6447 - val_loss: 1.5330 - val_accuracy: 0.5814\n",
      "Epoch 198/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2007 - accuracy: 0.6440 - val_loss: 1.5361 - val_accuracy: 0.5766\n",
      "Epoch 199/250\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 1.1806 - accuracy: 0.6525 - val_loss: 1.5502 - val_accuracy: 0.5802\n",
      "Epoch 200/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1986 - accuracy: 0.6465 - val_loss: 1.5073 - val_accuracy: 0.5884\n",
      "Epoch 201/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2009 - accuracy: 0.6443 - val_loss: 1.5490 - val_accuracy: 0.5837\n",
      "Epoch 202/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1905 - accuracy: 0.6499 - val_loss: 1.5437 - val_accuracy: 0.5783\n",
      "Epoch 203/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1992 - accuracy: 0.6451 - val_loss: 1.5258 - val_accuracy: 0.5840\n",
      "Epoch 204/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1941 - accuracy: 0.6508 - val_loss: 1.5184 - val_accuracy: 0.5837\n",
      "Epoch 205/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2006 - accuracy: 0.6503 - val_loss: 1.5262 - val_accuracy: 0.5833\n",
      "Epoch 206/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1880 - accuracy: 0.6514 - val_loss: 1.5501 - val_accuracy: 0.5768\n",
      "Epoch 207/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1933 - accuracy: 0.6477 - val_loss: 1.5203 - val_accuracy: 0.5815\n",
      "Epoch 208/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1939 - accuracy: 0.6493 - val_loss: 1.6155 - val_accuracy: 0.5681\n",
      "Epoch 209/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1821 - accuracy: 0.6491 - val_loss: 1.5376 - val_accuracy: 0.5808\n",
      "Epoch 210/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1825 - accuracy: 0.6504 - val_loss: 1.5372 - val_accuracy: 0.5765\n",
      "Epoch 211/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1847 - accuracy: 0.6507 - val_loss: 1.5141 - val_accuracy: 0.5874\n",
      "Epoch 212/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1891 - accuracy: 0.6507 - val_loss: 1.5317 - val_accuracy: 0.5814\n",
      "Epoch 213/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1855 - accuracy: 0.6510 - val_loss: 1.5431 - val_accuracy: 0.5819\n",
      "Epoch 214/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1791 - accuracy: 0.6513 - val_loss: 1.5058 - val_accuracy: 0.5889\n",
      "Epoch 215/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1956 - accuracy: 0.6488 - val_loss: 1.5689 - val_accuracy: 0.5669\n",
      "Epoch 216/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1852 - accuracy: 0.6530 - val_loss: 1.5351 - val_accuracy: 0.5800\n",
      "Epoch 217/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1972 - accuracy: 0.6442 - val_loss: 1.5734 - val_accuracy: 0.5775\n",
      "Epoch 218/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1934 - accuracy: 0.6477 - val_loss: 1.5216 - val_accuracy: 0.5795\n",
      "Epoch 219/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1887 - accuracy: 0.6519 - val_loss: 1.5519 - val_accuracy: 0.5761\n",
      "Epoch 220/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1902 - accuracy: 0.6488 - val_loss: 1.5409 - val_accuracy: 0.5787\n",
      "Epoch 221/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1849 - accuracy: 0.6507 - val_loss: 1.5379 - val_accuracy: 0.5792\n",
      "Epoch 222/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1859 - accuracy: 0.6491 - val_loss: 1.5503 - val_accuracy: 0.5799\n",
      "Epoch 223/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1877 - accuracy: 0.6500 - val_loss: 1.5227 - val_accuracy: 0.5804\n",
      "Epoch 224/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1834 - accuracy: 0.6511 - val_loss: 1.5408 - val_accuracy: 0.5797\n",
      "Epoch 225/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1982 - accuracy: 0.6479 - val_loss: 1.5457 - val_accuracy: 0.5802\n",
      "Epoch 226/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1717 - accuracy: 0.6517 - val_loss: 1.5214 - val_accuracy: 0.5819\n",
      "Epoch 227/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1822 - accuracy: 0.6520 - val_loss: 1.5308 - val_accuracy: 0.5836\n",
      "Epoch 228/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1915 - accuracy: 0.6500 - val_loss: 1.5322 - val_accuracy: 0.5796\n",
      "Epoch 229/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1710 - accuracy: 0.6532 - val_loss: 1.5520 - val_accuracy: 0.5741\n",
      "Epoch 230/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2021 - accuracy: 0.6485 - val_loss: 1.5364 - val_accuracy: 0.5815\n",
      "Epoch 231/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1884 - accuracy: 0.6498 - val_loss: 1.5023 - val_accuracy: 0.5897\n",
      "Epoch 232/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1913 - accuracy: 0.6492 - val_loss: 1.5168 - val_accuracy: 0.5828\n",
      "Epoch 233/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1898 - accuracy: 0.6480 - val_loss: 1.5390 - val_accuracy: 0.5797\n",
      "Epoch 234/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1750 - accuracy: 0.6513 - val_loss: 1.5436 - val_accuracy: 0.5755\n",
      "Epoch 235/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1881 - accuracy: 0.6474 - val_loss: 1.5642 - val_accuracy: 0.5776\n",
      "Epoch 236/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1986 - accuracy: 0.6476 - val_loss: 1.5726 - val_accuracy: 0.5710\n",
      "Epoch 237/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1807 - accuracy: 0.6498 - val_loss: 1.5582 - val_accuracy: 0.5755\n",
      "Epoch 238/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2013 - accuracy: 0.6485 - val_loss: 1.5121 - val_accuracy: 0.5910\n",
      "Epoch 239/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1619 - accuracy: 0.6534 - val_loss: 1.5742 - val_accuracy: 0.5712\n",
      "Epoch 240/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1750 - accuracy: 0.6517 - val_loss: 1.5559 - val_accuracy: 0.5781\n",
      "Epoch 241/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1707 - accuracy: 0.6523 - val_loss: 1.5746 - val_accuracy: 0.5721\n",
      "Epoch 242/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1757 - accuracy: 0.6551 - val_loss: 1.5864 - val_accuracy: 0.5741\n",
      "Epoch 243/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1734 - accuracy: 0.6528 - val_loss: 1.5481 - val_accuracy: 0.5811\n",
      "Epoch 244/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1753 - accuracy: 0.6534 - val_loss: 1.5278 - val_accuracy: 0.5856\n",
      "Epoch 245/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1776 - accuracy: 0.6568 - val_loss: 1.5133 - val_accuracy: 0.5817\n",
      "Epoch 246/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1796 - accuracy: 0.6500 - val_loss: 1.5247 - val_accuracy: 0.5809\n",
      "Epoch 247/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1715 - accuracy: 0.6519 - val_loss: 1.5466 - val_accuracy: 0.5833\n",
      "Epoch 248/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1746 - accuracy: 0.6541 - val_loss: 1.5272 - val_accuracy: 0.5782\n",
      "Epoch 249/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1817 - accuracy: 0.6535 - val_loss: 1.5370 - val_accuracy: 0.5752\n",
      "Epoch 250/250\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.1653 - accuracy: 0.6550 - val_loss: 1.5425 - val_accuracy: 0.5845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8c104e0550>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDPZxHe3E-x7",
    "outputId": "87e529d3-91ec-41d4-96fa-ddb889bf9ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 1.5425 - accuracy: 0.5845\n",
      "Untrained model, accuracy: 58.45%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GVQ_FS2Dqs2A"
   },
   "outputs": [],
   "source": [
    "json_model = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WsRd0aLQqzvi"
   },
   "outputs": [],
   "source": [
    "nn_json = model.to_json()\n",
    "model_path = \"model_100.json\"\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(nn_json)\n",
    "# Save weights\n",
    "file_path = \"model_100.h5\"\n",
    "model.save_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "L4uNbUNjq2JM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# load json and create model\n",
    "with open(model_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model = model_from_json(model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mTVHrMzGq5XD"
   },
   "outputs": [],
   "source": [
    "scores = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QGVJOaBKq7MG"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import Accuracy, mean_squared_error, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_m2Ocxjq9pF",
    "outputId": "ffbe1d25-6b74-4516-caaf-606ab663d05e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXuVrc3drA8j",
    "outputId": "c1d6c524-1fdf-4ed8-de04-abacee1e0afa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5845"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(CategoricalAccuracy(y_test, scores))\n",
    "m = CategoricalAccuracy()\n",
    "m.update_state(y_test, scores)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seAgY9h8sxiT",
    "outputId": "4ac8bd17-c308-4d24-d83d-5368b91725ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Space_Savers_Image_Recognition100.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
